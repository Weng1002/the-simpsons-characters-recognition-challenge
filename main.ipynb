{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先安裝需要的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch \n",
    "!pip install torchvision   \n",
    "!pip install timm\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先定義資料增強的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import os\n",
    "import torchvision.transforms.v2 as T\n",
    "from PIL import Image\n",
    "\n",
    "# Custom transform to add Gaussian noise\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "# Custom transform to add Speckle noise\n",
    "class AddSpeckleNoise(object):\n",
    "    \"\"\"\n",
    "    Add speckle noise to the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_level=0.1):\n",
    "        \"\"\"\n",
    "        :param noise_level: Standard deviation of the noise distribution\n",
    "        \"\"\"\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: PyTorch tensor, the image on which noise is added\n",
    "        :return: PyTorch tensor, image with speckle noise\n",
    "        \"\"\"\n",
    "        # Generate speckle noise\n",
    "        noise = torch.randn_like(tensor) * self.noise_level\n",
    "\n",
    "        # Add speckle noise to the image\n",
    "        noisy_tensor = tensor * (1 + noise)\n",
    "\n",
    "        # Clip the values to be between 0 and 1\n",
    "        noisy_tensor = torch.clamp(noisy_tensor, 0, 1)\n",
    "\n",
    "        return noisy_tensor\n",
    "\n",
    "class AddPoissonNoise(object):\n",
    "    \"\"\"\n",
    "    Add Poisson noise to the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, lam=1.0):\n",
    "        \"\"\"\n",
    "        :param lam: Lambda parameter for Poisson distribution\n",
    "        \"\"\"\n",
    "        self.lam = lam\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: PyTorch tensor, the image to which noise is added\n",
    "        :return: PyTorch tensor, image with Poisson noise\n",
    "        \"\"\"\n",
    "        # Generate Poisson noise\n",
    "        noise = torch.poisson(self.lam * torch.ones(tensor.shape))\n",
    "\n",
    "        # Add Poisson noise to the image\n",
    "        noisy_tensor = tensor + noise / 255.0  # Assuming the image is scaled between 0 and 1\n",
    "\n",
    "        # Clip the values to be between 0 and 1\n",
    "        noisy_tensor = torch.clamp(noisy_tensor, 0, 1)\n",
    "\n",
    "        return noisy_tensor\n",
    "\n",
    "# Custom transform to add Salt and Pepper noise\n",
    "class AddSaltPepperNoise(object):\n",
    "    def __init__(self, salt_prob=0.05, pepper_prob=0.05):\n",
    "        self.salt_prob = salt_prob\n",
    "        self.pepper_prob = pepper_prob\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.rand(tensor.size())\n",
    "        tensor = tensor.clone()  # Clone the tensor to avoid modifying the original\n",
    "        \n",
    "        # Apply salt noise: setting some pixels to 1\n",
    "        tensor[noise < self.salt_prob] = 1\n",
    "        \n",
    "        # Apply pepper noise: setting some pixels to 0\n",
    "        tensor[noise > 1 - self.pepper_prob] = 0\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "\n",
    "# Define the image augmentation transformations\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),                     # 調整圖像大小\n",
    "    T.CenterCrop(224),                 # 中心裁剪至 224x224\n",
    "    T.ToTensor(),                      # 轉換為 Tensor\n",
    "    T.RandomHorizontalFlip(p=0.1),     # 水平翻轉\n",
    "    T.RandomVerticalFlip(p=0.1),       # 垂直翻轉\n",
    "    T.RandomRotation(10),              # 隨機旋轉\n",
    "    T.ColorJitter(0.4, 0.4, 0.4, 0.1), # 色彩抖動\n",
    "    T.RandomGrayscale(p=0.1),          # 灰階\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 正規化 (ViT 使用 ImageNet 的均值與標準差)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入數據集，以及區隔出訓練集和驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# 載入完整的訓練資料集\n",
    "full_dataset = datasets.ImageFolder(root='./train/train', transform=transform)\n",
    "\n",
    "# 設置拆分比例（例如 80% 用於訓練，20% 用於驗證）\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# 使用 random_split 進行拆分\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# # 檢查資料集類別\n",
    "class_names = full_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入 Pre-training 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  # 新增這一行\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "# 使用 torchvision 提供的 ViT 模型\n",
    "model = vit_b_16(pretrained=True).to(device)\n",
    "\n",
    "# 替換分類頭\n",
    "in_features = model.heads.head.in_features  # ViT 的輸出特徵數\n",
    "num_classes = len(class_names)  # 類別數量\n",
    "model.heads.head = nn.Sequential(\n",
    "    nn.Linear(in_features, 256),  # 隱藏層\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(256, num_classes)   # 輸出層\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定優化器和loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss()  # 分類任務中的標準損失函數\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4) # good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # 匯入 tqdm 模組\n",
    "import os  # 用於檔案操作\n",
    "\n",
    "num_epochs = 30  # 訓練的回合數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # 使用 Adam 優化器\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 使用交叉熵損失\n",
    "\n",
    "# 定義保存模型的目錄\n",
    "save_dir = \"./saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # 如果目錄不存在則創建\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 訓練模式\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 使用 tqdm 包裝 train_loader，顯示進度條\n",
    "    with tqdm(train_loader, unit=\"batch\") as train_progress:\n",
    "        train_progress.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in train_progress:\n",
    "            # 確保圖像與標籤移動至正確的設備\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 前向傳播與梯度更新\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 更新 tqdm 的描述訊息\n",
    "            train_progress.set_postfix(loss=(running_loss / len(train_loader)))\n",
    "\n",
    "    # 訓練損失輸出\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # 每 10 回\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def find_corrupted_images(root_dir):\n",
    "    corrupted_images = []\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            try:\n",
    "                img = Image.open(filepath)\n",
    "                img.verify()  # 僅驗證，不載入圖像\n",
    "            except (OSError, IOError):\n",
    "                print(f\"Corrupted image found: {filepath}\")\n",
    "                corrupted_images.append(filepath)\n",
    "    return corrupted_images\n",
    "\n",
    "# 檢查訓練和驗證資料夾\n",
    "corrupted_images = find_corrupted_images('./train/train')\n",
    "print(f\"Found {len(corrupted_images)} corrupted images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in corrupted_images:\n",
    "    os.remove(image_path)\n",
    "    print(f\"Deleted corrupted image: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "驗證模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # 設置模型為評估模式\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 關閉梯度計算，以節省記憶體\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Validation Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "\n",
    "# 提取類別名稱\n",
    "train_dir = './train/train'\n",
    "train_dataset = datasets.ImageFolder(root=train_dir)\n",
    "class_names = train_dataset.classes  # 提取類別名稱\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# 自定義 Dataset 類\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        # 過濾掉非圖像文件，僅保留 .jpg, .jpeg, .png 等格式\n",
    "        self.image_paths = sorted(\n",
    "            [f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f)) and f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        )\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 確保轉換為 RGB 格式\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, idx + 1  # 返回圖像與圖片的 ID（從 1 開始）\n",
    "\n",
    "# 定義圖像轉換\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加載測試資料集\n",
    "test_dir = './test-final/test-final'\n",
    "test_dataset = TestDataset(root_dir=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Loaded {len(test_dataset)} test images.\")\n",
    "\n",
    "# 模型推理\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in test_loader:  # `ids` 是自定義的圖片 ID\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)  # 獲取預測的類別索引\n",
    "\n",
    "        # 保存每張圖片的預測結果\n",
    "        for img_id, pred in zip(ids, predicted):\n",
    "            predictions.append({'id': img_id.item(), 'character': class_names[pred.item()]})\n",
    "\n",
    "# 按 ID 排序，確保輸出結果有序\n",
    "predictions = sorted(predictions, key=lambda x: x['id'])\n",
    "\n",
    "# 將結果保存到 CSV 文件\n",
    "submission_df = pd.DataFrame(predictions)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2、Compute the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 計算混淆矩陣\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds, labels=np.arange(len(class_names)))\n",
    "\n",
    "# 繪製熱力圖\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix (50x50)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# 保存混淆矩陣熱力圖為圖片\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3、Visualization and Understanding  Convoutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 定義存檔資料夾\n",
    "output_dir = \"./Task3\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # 如果資料夾不存在則創建\n",
    "\n",
    "# 定義可視化並保存 Filter 權重的函數\n",
    "def visualize_filters(layer, layer_name):\n",
    "    weights = layer.weight.data.cpu()  # 提取權重\n",
    "    num_filters = weights.shape[0]  # 濾波器數量\n",
    "    cols = 8  # 每行顯示的濾波器數量\n",
    "    rows = num_filters // cols + 1\n",
    "\n",
    "    # 聚合多通道權重（取平均值），轉換為 2D 圖像\n",
    "    weights_aggregated = weights.mean(dim=1)  # shape: (num_filters, height, width)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < num_filters:\n",
    "            ax.imshow(weights_aggregated[i].numpy(), cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"Filters in {layer_name}\", fontsize=16)\n",
    "    \n",
    "    # 儲存圖片\n",
    "    output_path = os.path.join(output_dir, f\"{layer_name}_filters.png\")\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    print(f\"Saved filters for layer {layer_name} to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 定義可視化並保存 Feature Map 的函數\n",
    "def visualize_feature_maps(feature_maps, layer_name):\n",
    "    feature_map = feature_maps[0].squeeze(0)  # 移除 batch 維度，shape: (channels, height, width)\n",
    "    num_channels = feature_map.shape[0]\n",
    "\n",
    "    cols = 8  # 每行顯示的通道數量\n",
    "    rows = num_channels // cols + 1\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    for i in range(rows * cols):\n",
    "        ax = axes[i // cols, i % cols]\n",
    "        if i < num_channels:\n",
    "            ax.imshow(feature_map[i].cpu(), cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(f\"Feature Maps in {layer_name}\", fontsize=16)\n",
    "    \n",
    "    # 儲存圖片\n",
    "    output_path = os.path.join(output_dir, f\"{layer_name}_feature_maps.png\")\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    print(f\"Saved feature maps for layer {layer_name} to {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 載入 ResNet18 模型\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# 註冊 Hook 以提取特徵圖\n",
    "feature_maps = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    feature_maps[module] = output  # 保存每層的輸出特徵圖\n",
    "\n",
    "# 註冊 Hook 到所有卷積層\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        hooks.append(module.register_forward_hook(hook_fn))\n",
    "\n",
    "# 準備圖像轉換\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 載入測試圖像\n",
    "image_path = './test-final/test-final/2.jpg'   # 替換為您的測試圖像路徑\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "input_tensor = transform(image).unsqueeze(0)  # 增加 batch 維度\n",
    "\n",
    "# 模型推理，提取特徵圖\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model(input_tensor)\n",
    "\n",
    "# 移除 Hook\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# 可視化並保存每層的濾波器權重\n",
    "print(\"Visualizing and saving Filters...\")\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        visualize_filters(module, name)\n",
    "\n",
    "# 可視化並保存每層的特徵圖\n",
    "print(\"Visualizing and saving Feature Maps...\")\n",
    "for module, fmap in feature_maps.items():\n",
    "    visualize_feature_maps(fmap, str(module))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
